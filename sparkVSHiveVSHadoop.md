Hadoop is an ecosystem (HDFS + Mapreduce), but commonly used to reference the storage part of it (HDFS).

Spark is a tool to transform data in memory (opposed to map-reduce, where intermediate results were written to disk).

Hive stores metadata about your parquet, csv, orc, or other files that are stored on HDFS, and allows you to query it using HQL (HiveQL).

